{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import ast\n",
    "import os\n",
    "import argparse\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(base_path)\n",
    "\n",
    "print(\"Base path added to sys.path:\", base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# hyperparametr\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dropout_prob = 0.2\n",
    "test_batch_size = 1 # must be fixed to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_args(custom_args=None):\n",
    "    \"\"\"\n",
    "    make parser to get parameters\n",
    "    \"\"\"\n",
    "\n",
    "    parser = argparse.ArgumentParser(\n",
    "        prog='VAE',\n",
    "        description='using VAE for 768 dimensional data')\n",
    "    \n",
    "    parser.add_argument('--filename', type = str, default = 'prospectus_investment_objective.txt', help='source txt file')\n",
    "    parser.add_argument('--model_savefolder', type = str, default = 'model/state', help='best model save folder')\n",
    "    \n",
    "    \n",
    "\n",
    "    # Parse arguments\n",
    "    if custom_args:\n",
    "        return parser.parse_args(custom_args)\n",
    "    else:\n",
    "        return parser.parse_args()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe):\n",
    "        \n",
    "        self.vector = dataframe[4]\n",
    "        self.id = dataframe[0]\n",
    "        self.name = dataframe[1]\n",
    "        self.type_no = dataframe[2]\n",
    "        self.sentence = dataframe[3]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        vector_data = np.array(ast.literal_eval(self.vector[index])).astype(np.float32)\n",
    "        criteria_no = int(self.type_no[index])\n",
    "        return vector_data, self.id[index], self.name[index], criteria_no, self.sentence[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.vector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     \n",
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim=768, hidden_dim=[600, 500, 400, 300, 200, 100, 50], latent_dim = 2, device=device):\n",
    "        \n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim[0]),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_prob), \n",
    "            nn.Linear(hidden_dim[0], hidden_dim[1]),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_prob), \n",
    "            nn.Linear(hidden_dim[1], hidden_dim[2]),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_prob), \n",
    "            nn.Linear(hidden_dim[2], hidden_dim[3]),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_prob), \n",
    "            nn.Linear(hidden_dim[3], hidden_dim[4]),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_prob), \n",
    "            nn.Linear(hidden_dim[4], hidden_dim[5]),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_prob), \n",
    "            nn.Linear(hidden_dim[5], hidden_dim[6]),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_prob), \n",
    "            nn.Linear(hidden_dim[6], latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "            )\n",
    "        \n",
    "        # latent mean and variance \n",
    "        self.mean_layer = nn.Linear(latent_dim, 2)\n",
    "        self.logvar_layer = nn.Linear(latent_dim, 2)\n",
    "        \n",
    "        # decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, latent_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_prob), \n",
    "            nn.Linear(latent_dim, hidden_dim[6]),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_prob), \n",
    "            nn.Linear(hidden_dim[6], hidden_dim[5]),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_prob), \n",
    "            nn.Linear(hidden_dim[5], hidden_dim[4]),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_prob), \n",
    "            nn.Linear(hidden_dim[4], hidden_dim[3]),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_prob), \n",
    "            nn.Linear(hidden_dim[3], hidden_dim[2]),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_prob), \n",
    "            nn.Linear(hidden_dim[2], hidden_dim[1]),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_prob), \n",
    "            nn.Linear(hidden_dim[1], hidden_dim[0]),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_prob), \n",
    "            nn.Linear(hidden_dim[0], input_dim),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "     \n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mean, logvar = self.mean_layer(x), self.logvar_layer(x)\n",
    "        return mean, logvar, x\n",
    "\n",
    "    def reparameterization(self, mean, var):\n",
    "        epsilon = torch.randn_like(var).to(device)      \n",
    "        z = mean + var*epsilon\n",
    "        return z\n",
    "\n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar, _ = self.encode(x)\n",
    "        z = self.reparameterization(mean, logvar)\n",
    "        x_hat = self.decode(z)\n",
    "        return x_hat, mean, logvar\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def inference(args, device, test_loader, output_file, x_dim=768):\n",
    "    \n",
    "    # loading model\n",
    "    model_path = os.path.join(base_path, args.model_savefolder, 'vae_model_best.pth') \n",
    "    print('loading model for inference: ', model_path)\n",
    "    model = torch.load(model_path)\n",
    "    model.eval()\n",
    "    inference_size = 1\n",
    "    \n",
    "    for batch_idx, xf in enumerate(test_loader):\n",
    "     \n",
    "        x = xf[0]\n",
    "        x = x.view(inference_size, x_dim).to(device)\n",
    "        \n",
    "        mean, logvar, output_vector = model.encode(x)\n",
    "       \n",
    "        \n",
    "        str_output = str(output_vector.detach().cpu().numpy().flatten())\n",
    "        # print(str_output)\n",
    "        \n",
    "        test_id = ' '.join(str(value) for value in xf[1])\n",
    "        # print(test_id)\n",
    "        \n",
    "        test_name = ' '.join(str(value) for value in xf[2])\n",
    "        # print(test_name)\n",
    "        \n",
    "        test_criteria_no = str(xf[3].item())\n",
    "        # print(test_criteria_no)\n",
    "        \n",
    "        test_sentence = ' '.join(str(value) for value in xf[4])\n",
    "        # print(test_sentence)\n",
    "        \n",
    "        write_str = test_id + '\\t' + test_name + '\\t' + test_criteria_no + '\\t' + str_output + '\\t' + test_sentence \n",
    "        print(write_str)\n",
    "        \n",
    "        # output_filename = os.path.join(args.inference_output_folder, args.compressed_filename)\n",
    "        \n",
    "        \n",
    "        with open(output_file, 'a', encoding='utf-8') as file:\n",
    "            file.write(write_str + '\\n')\n",
    "        \n",
    "    return output_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    \n",
    "    # args\n",
    "    custom_args = ['--filename', 'data/prospectus_investment_objective.txt', '--model_savefolder', 'model/state']  \n",
    "    args = get_args(custom_args)\n",
    "\n",
    "    basedir = os.path.dirname(args.filename)\n",
    "    print('basedir: ', basedir)\n",
    "    basename = os.path.basename(args.filename)\n",
    "    \n",
    "    output_file = os.path.join(base_path, basedir, \"compressed_\" + basename)\n",
    "    \n",
    "\n",
    "    # Remove the output file if it exists.\n",
    "    if os.path.exists(output_file):\n",
    "        os.remove(output_file)\n",
    "\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(base_path, args.filename), sep=\"\\t\", header=None) \n",
    "    dataset = CustomDataset(dataframe=df)\n",
    "    data_loader = DataLoader(dataset=dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "    inference(args, device, data_loader, output_file)\n",
    "    print('inference finished')\n",
    "\n",
    "    return\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hand_obj_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
